{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Calendar Information\n",
    "import datetime\n",
    "import holidays\n",
    "import calendar\n",
    "\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# Data Preprocessing\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Modeling and Forecasting\n",
    "import optuna\n",
    "from lightgbm import LGBMRegressor, early_stopping, log_evaluation\n",
    "from tensorflow.keras import models, layers, callbacks, Input\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
    "\n",
    "# Other\n",
    "import os\n",
    "import joblib\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base path for saving plots\n",
    "base_path_plots = \"/Users/Vageli/Desktop/DABN01/plots/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load energy output data\n",
    "output = pd.read_csv(\n",
    "    '/Users/Vageli/Desktop/DABN01/data/energy_quant_sols1_data/measurements.csv',\n",
    "    sep=';',\n",
    "    decimal=','\n",
    ")\n",
    "\n",
    "# Set index and name it 'datetime'\n",
    "output.index = pd.to_datetime(output['Index'], format='%d.%m.%Y %H:%M')\n",
    "output.index.name = 'datetime'\n",
    "\n",
    "# Drop the original 'Index' column\n",
    "output.drop(columns=['Index'], inplace=True)\n",
    "\n",
    "# Rename the first column to 'output'\n",
    "output.rename(columns={output.columns[0]: 'output'}, inplace=True)\n",
    "\n",
    "# Check timezone info\n",
    "print(output.index.tz)\n",
    "\n",
    "# Convert to CET and handle DST properly\n",
    "output_dst = output.tz_localize('CET', ambiguous='infer')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTC+01:00\n"
     ]
    }
   ],
   "source": [
    "# Load temperature data\n",
    "temperature = pd.read_csv(\n",
    "    '/Users/Vageli/Desktop/DABN01/data/energy_quant_sols1_data/temperature_stuttgart_h.csv',\n",
    "    sep=',',\n",
    "    decimal='.',\n",
    "    index_col=0,\n",
    "    parse_dates=True\n",
    ")\n",
    "\n",
    "# Rename index and first column\n",
    "temperature.index.name = 'datetime'\n",
    "temperature.rename(columns={temperature.columns[0]: 'temperature'}, inplace=True)\n",
    "\n",
    "# Check timezone info\n",
    "print(temperature.index.tz)\n",
    "\n",
    "# Convert to CET\n",
    "temperature_dst = temperature.tz_convert('CET')\n",
    "\n",
    "# Upsample to quarter-hourly frequency and forward fill\n",
    "temperature_dst = temperature_dst.resample('15min').ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Into Single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-01 00:00:00+01:00\n",
      "2024-12-16 23:45:00+01:00\n",
      "Number of observations: 173952\n"
     ]
    }
   ],
   "source": [
    "# Merge into a single DataFrame\n",
    "data = output_dst.join(temperature_dst, how='left')\n",
    "\n",
    "# Drop NaNs\n",
    "data = data.dropna()\n",
    "\n",
    "# Check dates in merged dataset\n",
    "print(data.index.min())\n",
    "print(data.index.max())\n",
    "\n",
    "# Print data length\n",
    "print(f'Number of observations: {len(data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 173952 entries, 2020-01-01 00:00:00+01:00 to 2024-12-16 23:45:00+01:00\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   output       173952 non-null  float64\n",
      " 1   temperature  173952 non-null  float64\n",
      "dtypes: float64(2)\n",
      "memory usage: 4.0 MB\n"
     ]
    }
   ],
   "source": [
    "# Show missing values per column\n",
    "data.info()\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Holiday Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set of German holidays (province:'BW' for Baden-WÃ¼rttemberg)\n",
    "de_holidays = holidays.Germany(prov='BW', years=range(data.index.year.min(), data.index.year.max() + 1))\n",
    "\n",
    "# Encode as 1 if the date is a national holiday\n",
    "data['is_holiday'] = data.index.map(lambda x: 1 if x.date() in de_holidays else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cyclical Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract temporal information\n",
    "data['hour'] = data.index.hour           # 0-23\n",
    "data['dayofweek'] = data.index.dayofweek  # 0-6\n",
    "data['month'] = data.index.month          # 1-12\n",
    "\n",
    "# Define cyclical transformers\n",
    "def sin_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.sin(2 * np.pi * x / period))\n",
    "\n",
    "def cos_transformer(period):\n",
    "    return FunctionTransformer(lambda x: np.cos(2 * np.pi * x / period))\n",
    "\n",
    "# Apply cyclical encoding\n",
    "data['hour_sin'] = sin_transformer(24).fit_transform(data[['hour']])\n",
    "data['hour_cos'] = cos_transformer(24).fit_transform(data[['hour']])\n",
    "\n",
    "data['dayofweek_sin'] = sin_transformer(7).fit_transform(data[['dayofweek']])\n",
    "data['dayofweek_cos'] = cos_transformer(7).fit_transform(data[['dayofweek']])\n",
    "\n",
    "data['month_sin'] = sin_transformer(12).fit_transform(data[['month']])\n",
    "data['month_cos'] = cos_transformer(12).fit_transform(data[['month']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lags of Response Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lag features\n",
    "data['lag_1w'] = data['output'].shift(672)     # 1 week\n",
    "data['lag_1m'] = data['output'].shift(2880)    # 1 month\n",
    "data['lag_1y'] = data['output'].shift(35040)   # 1 year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rolling Windows of Temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create rolling window features for temperature\n",
    "data['temp_roll_mean_1_day'] = data['temperature'].rolling(window=96).mean()\n",
    "data['temp_roll_mean_7_day'] = data['temperature'].rolling(window=96 * 7).mean()\n",
    "\n",
    "data['temp_roll_max_1_day'] = data['temperature'].rolling(window=96).max()\n",
    "data['temp_roll_min_1_day'] = data['temperature'].rolling(window=96).min()\n",
    "\n",
    "data['temp_roll_max_7_day'] = data['temperature'].rolling(window=96 * 7).max()\n",
    "data['temp_roll_min_7_day'] = data['temperature'].rolling(window=96 * 7).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with NaNs caused by shifting\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 138912 entries, 2020-12-31 00:00:00+01:00 to 2024-12-16 23:45:00+01:00\n",
      "Data columns (total 21 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   output                138912 non-null  float64\n",
      " 1   temperature           138912 non-null  float64\n",
      " 2   is_holiday            138912 non-null  int64  \n",
      " 3   hour                  138912 non-null  int32  \n",
      " 4   dayofweek             138912 non-null  int32  \n",
      " 5   month                 138912 non-null  int32  \n",
      " 6   hour_sin              138912 non-null  float64\n",
      " 7   hour_cos              138912 non-null  float64\n",
      " 8   dayofweek_sin         138912 non-null  float64\n",
      " 9   dayofweek_cos         138912 non-null  float64\n",
      " 10  month_sin             138912 non-null  float64\n",
      " 11  month_cos             138912 non-null  float64\n",
      " 12  lag_1w                138912 non-null  float64\n",
      " 13  lag_1m                138912 non-null  float64\n",
      " 14  lag_1y                138912 non-null  float64\n",
      " 15  temp_roll_mean_1_day  138912 non-null  float64\n",
      " 16  temp_roll_mean_7_day  138912 non-null  float64\n",
      " 17  temp_roll_max_1_day   138912 non-null  float64\n",
      " 18  temp_roll_min_1_day   138912 non-null  float64\n",
      " 19  temp_roll_max_7_day   138912 non-null  float64\n",
      " 20  temp_roll_min_7_day   138912 non-null  float64\n",
      "dtypes: float64(17), int32(3), int64(1)\n",
      "memory usage: 21.7 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Funcitons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create funciton that calculates and prints evaluation metrics\n",
    "def evaluate_regression_metrics(y_true, y_pred, label=\"Model\"):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    \n",
    "    print(f\"--- {label} Evaluation ---\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.2f} kW\")\n",
    "    print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f} %\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f} kW\")\n",
    "    \n",
    "    return {\"MAE\": mae, \"MAPE\": mape, \"RMSE\": rmse}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive Plot (Prediction vs Actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions(y_true, y_pred, dates=None, title=\"Prediction vs Actual Output\", label=\"Model\"):\n",
    "    fig = go.Figure()\n",
    "    x_axis = dates if dates is not None else list(range(len(y_true)))\n",
    "\n",
    "    fig.add_trace(go.Scatter(x=x_axis, y=y_true, mode='lines', name='Actual Output'))\n",
    "    fig.add_trace(go.Scatter(x=x_axis, y=y_pred, mode='lines', name=f'Predicted Output ({label})'))\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=title,\n",
    "        xaxis_title=\"Time\" if dates is not None else \"Time Step (15-min intervals)\",\n",
    "        yaxis_title=\"Output (kW)\",\n",
    "        legend=dict(x=0, y=1.1, orientation='h'),\n",
    "        height=400,\n",
    "        width=900,\n",
    "        margin=dict(l=40, r=40, t=40, b=40)\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot (Prediction vs Actual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_predictions(datetime_series, y_true, y_pred, \n",
    "                              filename, \n",
    "                              base_path=base_path_plots,\n",
    "                              xlabel=\"Date\", ylabel=\"Energy Output (kW)\"):\n",
    "    \n",
    "    # Full save path\n",
    "    save_path = f\"{base_path}{filename}.png\"\n",
    "    \n",
    "    # Create plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.plot(datetime_series, y_true, label='Actual', linewidth=2)\n",
    "    ax.plot(datetime_series, y_pred, label='Predicted', color='red', linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel(xlabel, fontsize=12)\n",
    "    ax.set_ylabel(ylabel, fontsize=12)\n",
    "    ax.grid(True, linestyle='--', alpha=0.7)\n",
    "    ax.legend(loc='upper right', fontsize=12)\n",
    "    \n",
    "    fig.autofmt_xdate()  # Auto-format date labels\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    fig.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Plot saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot (Residual Dianostics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_save_residuals(datetime_series, y_true, y_pred, \n",
    "                            filename, \n",
    "                            base_path=base_path_plots):\n",
    "    \n",
    "     # Full save path\n",
    "    save_path = f\"{base_path}{filename}.png\"\n",
    "\n",
    "    # Calculate residuals\n",
    "    residuals = y_true - y_pred\n",
    "\n",
    "    # Create plot\n",
    "    fig = plt.figure(figsize=(12, 8))\n",
    "    gs = fig.add_gridspec(2, 2, height_ratios=[2, 1.5])\n",
    "\n",
    "    # Residuals over time\n",
    "    ax1 = fig.add_subplot(gs[0, :])\n",
    "    ax1.plot(datetime_series, residuals, color='steelblue')\n",
    "    ax1.axhline(0, linestyle='--', color='gray')\n",
    "    ax1.set_ylabel(\"Residual (kW)\")\n",
    "    ax1.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "    # ACF\n",
    "    ax2 = fig.add_subplot(gs[1, 0])\n",
    "    ax2.set_ylabel(\"ACF\")\n",
    "    plot_acf(residuals, lags=40, ax=ax2)\n",
    "\n",
    "    # Histogram\n",
    "    ax3 = fig.add_subplot(gs[1, 1])\n",
    "    ax3.set_ylabel(\"Count\")\n",
    "    sns.histplot(residuals, bins=30, kde=True, color='salmon', ax=ax3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot (Prediction vs. Actual) for a Few Selected Weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_and_save_weekly_predictions(datetime_series, y_true, y_pred, \n",
    "                                     filename, \n",
    "                                     base_path=base_path_plots,\n",
    "                                     steps_per_week=96 * 7,  # 1 week of 15-min intervals\n",
    "                                     weeks_to_plot=9):\n",
    "    \n",
    "    # Full save path\n",
    "    save_path = f\"{base_path}{filename}.png\"\n",
    "    \n",
    "    total_steps = len(y_true)\n",
    "    start_indices = np.linspace(0, total_steps - steps_per_week, weeks_to_plot, dtype=int)\n",
    "    \n",
    "    fig, axes = plt.subplots(3, 3, figsize=(15, 10), sharey=True)\n",
    "    \n",
    "    for idx, ax in enumerate(axes.flatten()):\n",
    "        start = start_indices[idx]\n",
    "        end = start + steps_per_week\n",
    "\n",
    "        # Extract corresponding dates for titles\n",
    "        start_date = datetime_series[start].strftime('%Y-%m-%d')\n",
    "        end_date = datetime_series[end - 1].strftime('%Y-%m-%d')\n",
    "\n",
    "        # Plot actual and predicted\n",
    "        ax.plot(y_true[start:end], label='Actual', linewidth=2)\n",
    "        ax.plot(y_pred[start:end], label='Predicted', color='red', linewidth=2)\n",
    "        ax.set_title(f'Week: {start_date} to {end_date}', fontsize=10)\n",
    "        ax.grid(True, linestyle='--', alpha=0.6)\n",
    "        \n",
    "        if idx % 3 == 0:\n",
    "            ax.set_ylabel('Output (kW)', fontsize=10)\n",
    "        if idx >= 6:\n",
    "            ax.set_xlabel('Time Steps', fontsize=10)\n",
    "    \n",
    "    fig.legend(['Actual', 'Predicted'], loc='upper center', ncol=2, fontsize=12)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "\n",
    "    # Save figure\n",
    "    fig.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Weekly predictions plot saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model I: LightGBM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define Target and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features for LightGBM\n",
    "features_lgbm = [\n",
    "    'temperature',\n",
    "    'is_holiday',\n",
    "    'lag_1w', 'lag_1m', 'lag_1y',\n",
    "    'hour_sin', 'hour_cos',\n",
    "    'dayofweek_sin', 'dayofweek_cos',\n",
    "    'month_sin', 'month_cos',\n",
    "    'temp_roll_mean_1_day',\n",
    "    'temp_roll_mean_7_day',\n",
    "    'temp_roll_max_1_day',\n",
    "    'temp_roll_min_1_day',\n",
    "    'temp_roll_max_7_day',\n",
    "    'temp_roll_min_7_day'\n",
    "]\n",
    "\n",
    "# Define target\n",
    "target = 'output'\n",
    "\n",
    "# Create input and output data for LightGBM\n",
    "X_lgbm = data[features_lgbm]\n",
    "y_lgbm = data[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case that all data should be imputed, more predictions are needed. Thus, a 50/50 split is done. Otherwise, an 80/20 split is done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that decides the split based on the imputation strategy used\n",
    "# 'test: An 80/20 split used for the test-time imputation strategy\n",
    "# 'all': A 50/50 split used for the train-time imputation strategy\n",
    "def determine_split(impute_type):\n",
    "    if impute_type == 'all':\n",
    "        split = 0.5\n",
    "    elif impute_type == 'test':\n",
    "        split = 0.8\n",
    "    else:\n",
    "        raise ValueError(\"Invalid impute_type. Choose 'all' or 'test'.\")\n",
    "    \n",
    "    return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (111129, 17)\n",
      "y_train shape: (111129,)\n",
      "X_test shape: (27783, 17)\n",
      "y_test shape: (27783,)\n",
      "Train period: 2020-12-31 to 2024-03-02\n",
      "Test period:  2024-03-02 to 2024-12-16\n"
     ]
    }
   ],
   "source": [
    "# Train-test split\n",
    "split = determine_split(impute_type='test')\n",
    "split_idx = int(split * len(X_lgbm))\n",
    "\n",
    "X_train_lgbm, X_test_lgbm = X_lgbm[:split_idx], X_lgbm[split_idx:]\n",
    "y_train_lgbm, y_test_lgbm = y_lgbm[:split_idx], y_lgbm[split_idx:]\n",
    "\n",
    "# Store corresponding dates for plotting\n",
    "datetime_train_lgbm = y_lgbm.index[:split_idx]\n",
    "datetime_test_lgbm = y_lgbm.index[split_idx:]\n",
    "\n",
    "print(\"X_train shape:\", X_train_lgbm.shape)\n",
    "print(\"y_train shape:\", y_train_lgbm.shape)\n",
    "\n",
    "print(\"X_test shape:\", X_test_lgbm.shape)\n",
    "print(\"y_test shape:\", y_test_lgbm.shape)\n",
    "\n",
    "# Print date intervals for train and test sets\n",
    "print(f\"Train period: {datetime_train_lgbm[0].date()} to {datetime_train_lgbm[-1].date()}\")\n",
    "print(f\"Test period:  {datetime_test_lgbm[0].date()} to {datetime_test_lgbm[-1].date()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper-Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# Optuna Objective Function\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective'         : 'regression',\n",
    "        'metric'            : 'rmse',\n",
    "        'boosting_type'     : 'gbdt',\n",
    "        'verbosity'         : -1,\n",
    "        'n_estimators'      : 1000,\n",
    "        'num_leaves'        : trial.suggest_int('num_leaves', 8, 256, step=8),\n",
    "        'max_depth'         : trial.suggest_int('max_depth', 3, 15),\n",
    "        'min_child_samples' : trial.suggest_int('min_child_samples', 5, 100, step=5),\n",
    "        'learning_rate'     : trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "        'subsample'         : trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree'  : trial.suggest_float('colsample_bytree', 0.5, 1),\n",
    "        'max_bin'           : trial.suggest_int('max_bin', 50, 250, step=25),\n",
    "        'reg_alpha'         : trial.suggest_float('reg_alpha', 1e-4, 1, log=True),\n",
    "        'reg_lambda'        : trial.suggest_float('reg_lambda', 1e-4, 1, log=True)\n",
    "    }\n",
    "\n",
    "    model = LGBMRegressor(**params)\n",
    "\n",
    "    model.fit(\n",
    "        X_train_lgbm, y_train_lgbm,\n",
    "        eval_set=[(X_test_lgbm, y_test_lgbm)],\n",
    "        callbacks=[\n",
    "            early_stopping(stopping_rounds=50)]\n",
    "    )\n",
    "\n",
    "    preds = model.predict(X_test_lgbm)\n",
    "    rmse = root_mean_squared_error(y_test_lgbm, preds)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Optuna optimization\n",
    "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study = optuna.create_study(direction='minimize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Store best parameters\n",
    "best_params = study.best_trial.params\n",
    "print('Best RMSE:', study.best_trial.value)\n",
    "print('Best Params:', best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/ Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with Best Parameters\n",
    "model_lgbm = LGBMRegressor(**best_params, n_estimators=1000)\n",
    "\n",
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "model_lgbm.fit(\n",
    "    X_train_lgbm, y_train_lgbm,\n",
    "    eval_set=[(X_test_lgbm, y_test_lgbm)],\n",
    "    callbacks=[\n",
    "        early_stopping(stopping_rounds=50)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Record end time\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the model\n",
    "# joblib.dump(model_lgbm, \"/Users/Vageli/Desktop/DABN01/models/best_lgbm_model_all.pkl\")\n",
    "\n",
    "# # Load optimized model\n",
    "# model_lgbm = joblib.load(\"/Users/Vageli/Desktop/DABN01/models/best_lgbm_model_all.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate elapsed time in seconds\n",
    "training_time_lgbm = end_time - start_time\n",
    "\n",
    "# Format as minutes and seconds\n",
    "training_time_minutes = training_time_lgbm / 60\n",
    "print(f\"Training Time: {training_time_lgbm:.2f} seconds ({training_time_minutes:.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- LightGBM Evaluation ---\n",
      "Mean Absolute Error (MAE): 533.77 kW\n",
      "Mean Absolute Percentage Error (MAPE): 10.69 %\n",
      "Root Mean Squared Error (RMSE): 757.11 kW\n"
     ]
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred_lgbm = model_lgbm.predict(X_test_lgbm)\n",
    "\n",
    "results_lgbm = pd.DataFrame({\n",
    "    'Prediction': y_pred_lgbm,\n",
    "    'Outcome': y_test_lgbm.values\n",
    "}, index=y_test_lgbm.index)\n",
    "\n",
    "# Evaluaion metrics\n",
    "metrics_lgbm = evaluate_regression_metrics(y_test_lgbm, y_pred_lgbm, label=\"LightGBM\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot interactive graph of predictions vs. actual output\n",
    "plot_predictions(y_test_lgbm.values, y_pred_lgbm, dates=datetime_test_lgbm, title=\"LGBM Predictions on Test Set\", label=\"LightGBM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate importance\n",
    "importance = pd.Series(model_lgbm.feature_importances_, index=X_lgbm.columns)\n",
    "importance = importance.sort_values(ascending=False)\n",
    "\n",
    "# Plot importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "importance.plot(kind='bar')\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.ylabel(\"Importance (Gain-based)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and store graph of predictions vs. actual output\n",
    "plot_and_save_predictions(\n",
    "    datetime_series=datetime_test_lgbm,\n",
    "    y_true=y_test_lgbm.values,\n",
    "    y_pred=y_pred_lgbm,\n",
    "    filename=\"predictions_full(model=lgbm)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and store graph of residuals\n",
    "plot_and_save_residuals(\n",
    "    datetime_series=datetime_test_lgbm,\n",
    "    y_true=y_test_lgbm.values,\n",
    "    y_pred=y_pred_lgbm,\n",
    "    filename=\"residuals(model=lgbm)\"\n",
    ")\n",
    "\n",
    "residuals = y_test_lgbm - y_pred_lgbm\n",
    "lb_test = acorr_ljungbox(residuals, lags=[10, 20, 30], return_df=True)\n",
    "print(\"Ljung-Box Test Results:\")\n",
    "print(lb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and store graph of predictions vs. actual output for a few selected weeks\n",
    "plot_and_save_weekly_predictions(\n",
    "    datetime_series=datetime_test_lgbm,\n",
    "    y_true=y_test_lgbm.values,\n",
    "    y_pred=y_pred_lgbm,\n",
    "    filename=\"predictions_week(model=lgbm)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data imputation using LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters \n",
    "SEQUENCE_LEN = 96 * 7 # Number of past time steps to include in each input sequence to predict the next value\n",
    "DELAY_LENGTH = 96 * 4 # Number of unavailable time steps that must be imputed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features\n",
    "feature_cols = [\n",
    "    'output',\n",
    "    'temperature',\n",
    "    'is_holiday',\n",
    "    'hour_sin', 'hour_cos',\n",
    "    'dayofweek_sin', 'dayofweek_cos',\n",
    "    'month_sin', 'month_cos'\n",
    "]\n",
    "\n",
    "# Convert DataFrame to NumPy Array \n",
    "data_lstm = data[feature_cols].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence alignment check: True\n"
     ]
    }
   ],
   "source": [
    "# Create sequences\n",
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(seq_length, len(data)):\n",
    "        X.append(data[i - seq_length:i])\n",
    "        y.append(data[i][0])  # Target: 'output'\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "X_lstm, y_lstm = create_sequences(data_lstm, SEQUENCE_LEN)\n",
    "datetime_index_lstm = data.index[SEQUENCE_LEN:] # Adjust DateTime index to fit sequence-data\n",
    "\n",
    "print(f\"Sequence alignment check: {len(data_lstm) - len(X_lstm) == SEQUENCE_LEN}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_and_split(X, y, y_pred_lgbm, delay_length, split_type='test'):\n",
    "    X_imputed = X.copy()\n",
    "\n",
    "    start_datetime = datetime_test_lgbm[0]\n",
    "    start_id = datetime_index_lstm.get_loc(start_datetime)\n",
    "    start_id_delay = start_id + delay_length\n",
    "\n",
    "    assert len(y_pred_lgbm) == len(X[start_id_delay:]) + delay_length, \"Predictions array too short for imputation.\"\n",
    "\n",
    "    # Imputation\n",
    "    for i in range(start_id_delay, len(X_imputed)):\n",
    "        preds_slice = y_pred_lgbm[i - start_id_delay : i - start_id_delay + delay_length]\n",
    "        X_imputed[i, -delay_length:, 0] = preds_slice\n",
    "\n",
    "    # Split logic: \n",
    "    #   If 'test': Only imputes the test data\n",
    "    #   If 'all': Splits data from where predictions start and performs an 80/20 train-test split\n",
    "    if split_type == 'test':\n",
    "        split_idx = start_id_delay\n",
    "\n",
    "        X_train, X_test = X_imputed[:split_idx], X_imputed[split_idx:]\n",
    "        y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "        datetime_train = datetime_index_lstm[:split_idx]\n",
    "        datetime_test = datetime_index_lstm[split_idx:]\n",
    "\n",
    "    elif split_type == 'all':\n",
    "        X_imputed = X_imputed[start_id_delay:]\n",
    "        y = y[start_id_delay:]\n",
    "        datetime_filtered = datetime_index_lstm[start_id_delay:]\n",
    "\n",
    "        split_idx = int(0.6 * len(X_imputed))\n",
    "\n",
    "        X_train, X_test = X_imputed[:split_idx], X_imputed[split_idx:]\n",
    "        y_train, y_test = y[:split_idx], y[split_idx:]\n",
    "\n",
    "        datetime_train = datetime_filtered[:split_idx]\n",
    "        datetime_test = datetime_filtered[split_idx:]\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Invalid split_type. Choose 'all' or 'test'.\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test, datetime_train, datetime_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (41443, 672, 9)\n",
      "y_train shape: (41443,)\n",
      "X_test shape: (27629, 672, 9)\n",
      "y_test shape: (27629,)\n",
      "Train period: 2022-12-28 to 2024-03-04\n",
      "Test period:  2024-03-04 to 2024-12-16\n"
     ]
    }
   ],
   "source": [
    "X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm, datetime_train_lstm, datetime_test_lstm = impute_and_split(\n",
    "    X_lstm,\n",
    "    y_lstm,\n",
    "    y_pred_lgbm,\n",
    "    DELAY_LENGTH,\n",
    "    split_type='all'\n",
    ")\n",
    "\n",
    "print(\"X_train shape:\", X_train_lstm.shape)\n",
    "print(\"y_train shape:\", y_train_lstm.shape)\n",
    "\n",
    "print(\"X_test shape:\", X_test_lstm.shape)\n",
    "print(\"y_test shape:\", y_test_lstm.shape)\n",
    "\n",
    "# Print date intervals for train and test sets\n",
    "print(f\"Train period: {datetime_train_lstm[0].date()} to {datetime_train_lstm[-1].date()}\")\n",
    "print(f\"Test period:  {datetime_test_lstm[0].date()} to {datetime_test_lstm[-1].date()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/ Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create normalization layer\n",
    "norm_layer = layers.Normalization()\n",
    "\n",
    "# Adapt it to your sequence training data (shape: (samples, timesteps, features))\n",
    "norm_layer.adapt(X_train_lstm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale target variable \n",
    "scaler_y = MinMaxScaler()\n",
    "y_train_lstm_scaled = scaler_y.fit_transform(y_train_lstm.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "input_shape = X_train_lstm.shape[1:]  # (timesteps, features)\n",
    "dropout_rate = 0.2\n",
    "lstm_units = 64\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "\n",
    "# Define the model\n",
    "model_lstm = models.Sequential([\n",
    "    Input(shape=input_shape),\n",
    "\n",
    "    norm_layer,\n",
    "\n",
    "    layers.LSTM(lstm_units, return_sequences=True),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.LSTM(lstm_units),\n",
    "    layers.Dropout(dropout_rate),\n",
    "\n",
    "    layers.Dense(1)\n",
    "])\n",
    "\n",
    "model_lstm.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Early stopping\n",
    "early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "model_lstm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record start time\n",
    "start_time = time.time()\n",
    "\n",
    "# Train the model\n",
    "history = model_lstm.fit(\n",
    "    X_train_lstm, y_train_lstm,\n",
    "    validation_split=0.2,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Record end time\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate elapsed time\n",
    "training_time_lstm = end_time - start_time\n",
    "\n",
    "# Format as minutes and seconds\n",
    "training_time_minutes = training_time_lstm / 60\n",
    "print(f\"Training Time: {training_time_lstm:.2f} seconds ({training_time_minutes:.2f} minutes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_training_history(history, title=\"Training vs Validation Loss\"):\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    plt.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
    "    plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2, linestyle='--')\n",
    "    \n",
    "    plt.title(title, fontsize=14)\n",
    "    plt.xlabel('Epochs', fontsize=12)\n",
    "    plt.ylabel('Loss (MSE)', fontsize=12)\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the loss curves\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and inverse transform\n",
    "y_pred_lstm_scaled = model_lstm.predict(X_test_lstm).flatten()\n",
    "y_pred_lstm = scaler_y.inverse_transform(y_pred_lstm_scaled.reshape(-1, 1)).flatten()\n",
    "\n",
    "results_lgbm = pd.DataFrame({\n",
    "    'Prediction': y_pred_lstm,\n",
    "    'Outcome': y_test_lstm\n",
    "}, index=datetime_test_lstm)\n",
    "\n",
    "# Evaluaion metrics\n",
    "metrics = evaluate_regression_metrics(y_test_lstm, y_pred_lstm, label=\"LSTM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot interactive graph of predictions vs. actual output\n",
    "plot_predictions(y_test_lstm, y_pred_lstm, dates=datetime_test_lstm, title=\"LSTM Predictions on Test Set\", label=\"LSTM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and store graph of predictions vs. actual output\n",
    "plot_and_save_predictions(\n",
    "    datetime_series=datetime_test_lstm,\n",
    "    y_true=y_test_lstm,\n",
    "    y_pred=y_pred_lstm,\n",
    "    filename=\"predictions_full(model=lstm,data=imput,seq=672,layer=2)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and store graph of residuals\n",
    "plot_and_save_residuals(\n",
    "    datetime_series=datetime_test_lstm,\n",
    "    y_true=y_test_lstm,\n",
    "    y_pred=y_pred_lstm,\n",
    "    filename=\"residuals(model=lstm,data=imput,seq=672,layer=2)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and store graph of predictions vs. actual output for a few selected weeks\n",
    "plot_and_save_weekly_predictions(\n",
    "    datetime_series=datetime_test_lstm,\n",
    "    y_true=y_test_lstm,\n",
    "    y_pred=y_pred_lstm,\n",
    "    filename=\"predictions_week(model=lstm,data=imput,seq=672,layer=2)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model III: Naive Seasonal Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set the lag period (1 week = 7 * 96 quarter-hours)\n",
    "lag_steps = 7 * 96\n",
    "\n",
    "# Test period start datetime (timezone-aware)\n",
    "test_start = pd.Timestamp(\"2024-03-06 13:15:00+00:00\")\n",
    "\n",
    "# Create shifted predictions based on last week's output\n",
    "seasonal_naive_pred = data['output'].shift(lag_steps)\n",
    "\n",
    "# Create new DataFrame for results (index remains datetime)\n",
    "seasonal_naive_results = pd.DataFrame({\n",
    "    'true_output': data['output'],\n",
    "    'seasonal_naive_pred': seasonal_naive_pred\n",
    "})\n",
    "\n",
    "# Filter to start from test period\n",
    "seasonal_naive_results = seasonal_naive_results.loc[test_start:]\n",
    "\n",
    "# Drop rows with NaN predictions\n",
    "seasonal_naive_results = seasonal_naive_results.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV, including the datetime index\n",
    "save_path = \"/Users/Vageli/Desktop/DABN01/data/seasonal_naive_predictions.csv\"\n",
    "seasonal_naive_results.to_csv(save_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dabe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
