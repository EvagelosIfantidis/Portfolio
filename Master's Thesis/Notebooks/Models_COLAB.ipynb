{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqU-gcnmlG8j"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna # Install Optuna to Colab"
      ],
      "metadata": {
        "id": "zU_pHV47lWEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbyBnAJolG8p"
      },
      "outputs": [],
      "source": [
        "# Data Processing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Calendar Information\n",
        "import datetime\n",
        "import holidays\n",
        "import calendar\n",
        "\n",
        "# Plotting\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "import seaborn as sns\n",
        "\n",
        "# Data Preprocessing\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Modeling and Forecasting\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "import optuna\n",
        "from lightgbm import LGBMRegressor, early_stopping, log_evaluation\n",
        "from tensorflow.keras import models, layers, callbacks, Input\n",
        "\n",
        "# Metrics\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import root_mean_squared_error\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "\n",
        "# Other\n",
        "import os\n",
        "import joblib\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7K85BwPWlG8q"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8UvWqCgYlG8q"
      },
      "source": [
        "### Energy Output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1syS2r_BlG8q"
      },
      "outputs": [],
      "source": [
        "# Load energy output data\n",
        "output = pd.read_csv(\n",
        "    'measurements.csv',\n",
        "    sep=';',\n",
        "    decimal=','\n",
        ")\n",
        "\n",
        "# Set index and name it 'datetime'\n",
        "output.index = pd.to_datetime(output['Index'], format='%d.%m.%Y %H:%M')\n",
        "output.index.name = 'datetime'\n",
        "\n",
        "# Drop the original 'Index' column\n",
        "output.drop(columns=['Index'], inplace=True)\n",
        "\n",
        "# Rename the first column to 'output'\n",
        "output.rename(columns={output.columns[0]: 'output'}, inplace=True)\n",
        "\n",
        "# Check timezone info\n",
        "print(output.index.tz)\n",
        "\n",
        "# Convert to CET and handle DST properly\n",
        "output_dst = output.tz_localize('CET', ambiguous='infer')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bb7ASBmblG8r"
      },
      "source": [
        "### Temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2MXhUm-flG8s"
      },
      "outputs": [],
      "source": [
        "# Load temperature data\n",
        "temperature = pd.read_csv(\n",
        "    'temperature_stuttgart_h.csv',\n",
        "    sep=',',\n",
        "    decimal='.',\n",
        "    index_col=0,\n",
        "    parse_dates=True\n",
        ")\n",
        "\n",
        "# Rename index and first column\n",
        "temperature.index.name = 'datetime'\n",
        "temperature.rename(columns={temperature.columns[0]: 'temperature'}, inplace=True)\n",
        "\n",
        "# Check timezone info\n",
        "print(temperature.index.tz)\n",
        "\n",
        "# Convert to CET\n",
        "temperature_dst = temperature.tz_convert('CET')\n",
        "\n",
        "# Upsample to quarter-hourly frequency and forward fill\n",
        "temperature_dst = temperature_dst.resample('15min').ffill()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dW7-8skOlG8s"
      },
      "source": [
        "### Merge Into Single DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNrNXbcVlG8s"
      },
      "outputs": [],
      "source": [
        "# Merge into a single DataFrame\n",
        "data = output_dst.join(temperature_dst, how='left')\n",
        "\n",
        "# Drop NaNs\n",
        "data = data.dropna()\n",
        "\n",
        "# Check dates in merged dataset\n",
        "print(data.index.min())\n",
        "print(data.index.max())\n",
        "\n",
        "# Print data length\n",
        "print(f'Number of observations: {len(data)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6qD3Ik0elG8s"
      },
      "outputs": [],
      "source": [
        "# Show missing values per column\n",
        "data.info()\n",
        "data = data.dropna()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVBORbIAlG8t"
      },
      "source": [
        "## Feature Engineering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10N4LU2vlG8t"
      },
      "source": [
        "### General Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HNhIT9ATlG8t"
      },
      "source": [
        "#### Holiday Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8Xxv_jmlG8t"
      },
      "outputs": [],
      "source": [
        "# Create a set of German holidays (province:'BW' for Baden-WÃ¼rttemberg)\n",
        "de_holidays = holidays.Germany(prov='BW', years=range(data.index.year.min(), data.index.year.max() + 1))\n",
        "\n",
        "# Encode as 1 if the date is a national holiday\n",
        "data['is_holiday'] = data.index.map(lambda x: 1 if x.date() in de_holidays else 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBFMPYKzlG8t"
      },
      "source": [
        "#### Cyclical Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GiWzOfCQlG8t"
      },
      "outputs": [],
      "source": [
        "# Extract temporal information\n",
        "data['hour'] = data.index.hour           # 0-23\n",
        "data['dayofweek'] = data.index.dayofweek  # 0-6\n",
        "data['month'] = data.index.month          # 1-12\n",
        "\n",
        "# Define cyclical transformers\n",
        "def sin_transformer(period):\n",
        "    return FunctionTransformer(lambda x: np.sin(2 * np.pi * x / period))\n",
        "\n",
        "def cos_transformer(period):\n",
        "    return FunctionTransformer(lambda x: np.cos(2 * np.pi * x / period))\n",
        "\n",
        "# Apply cyclical encoding\n",
        "data['hour_sin'] = sin_transformer(24).fit_transform(data[['hour']])\n",
        "data['hour_cos'] = cos_transformer(24).fit_transform(data[['hour']])\n",
        "\n",
        "data['dayofweek_sin'] = sin_transformer(7).fit_transform(data[['dayofweek']])\n",
        "data['dayofweek_cos'] = cos_transformer(7).fit_transform(data[['dayofweek']])\n",
        "\n",
        "data['month_sin'] = sin_transformer(12).fit_transform(data[['month']])\n",
        "data['month_cos'] = cos_transformer(12).fit_transform(data[['month']])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvIAu6bRlG8u"
      },
      "source": [
        "### LightGBM Features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTOOflEqlG8u"
      },
      "source": [
        "#### Lags of Response Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNPKsxOYlG8u"
      },
      "outputs": [],
      "source": [
        "# Create lag features\n",
        "data['lag_1w'] = data['output'].shift(672)     # 1 week\n",
        "data['lag_1m'] = data['output'].shift(2880)    # 1 month\n",
        "data['lag_1y'] = data['output'].shift(35040)   # 1 year"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vw3GpO-tlG8u"
      },
      "source": [
        "#### Rolling Windows of Temperature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PajSH2VElG8u"
      },
      "outputs": [],
      "source": [
        "# Create rolling window features for temperature\n",
        "data['temp_roll_mean_1_day'] = data['temperature'].rolling(window=96).mean()\n",
        "data['temp_roll_mean_7_day'] = data['temperature'].rolling(window=96 * 7).mean()\n",
        "\n",
        "data['temp_roll_max_1_day'] = data['temperature'].rolling(window=96).max()\n",
        "data['temp_roll_min_1_day'] = data['temperature'].rolling(window=96).min()\n",
        "\n",
        "data['temp_roll_max_7_day'] = data['temperature'].rolling(window=96 * 7).max()\n",
        "data['temp_roll_min_7_day'] = data['temperature'].rolling(window=96 * 7).min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8UK0Cd7lG8u"
      },
      "outputs": [],
      "source": [
        "# Drop rows with NaNs caused by shifting\n",
        "data.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "388Y2Un_lG8v"
      },
      "source": [
        "### Data Info"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2td4kV-lG8v"
      },
      "outputs": [],
      "source": [
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CQdb4CElG8v"
      },
      "source": [
        "## General Funcitons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9YFAkvtlG8v"
      },
      "source": [
        "### Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3-k-z6DlG8v"
      },
      "outputs": [],
      "source": [
        "# Create funciton that calculates and prints evaluation metrics\n",
        "def evaluate_regression_metrics(y_true, y_pred, label=\"Model\"):\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    mape = mean_absolute_percentage_error(y_true, y_pred) * 100\n",
        "    rmse = root_mean_squared_error(y_true, y_pred)\n",
        "\n",
        "    print(f\"--- {label} Evaluation ---\")\n",
        "    print(f\"Mean Absolute Error (MAE): {mae:.2f} kW\")\n",
        "    print(f\"Mean Absolute Percentage Error (MAPE): {mape:.2f} %\")\n",
        "    print(f\"Root Mean Squared Error (RMSE): {rmse:.2f} kW\")\n",
        "\n",
        "    return {\"MAE\": mae, \"MAPE\": mape, \"RMSE\": rmse}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5Md8IIBlG8v"
      },
      "source": [
        "### Interactive Plot (Prediction vs Actual)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwu3rMt5lG8w"
      },
      "outputs": [],
      "source": [
        "def plot_predictions(y_true, y_pred, dates=None, title=\"Prediction vs Actual Output\", label=\"Model\"):\n",
        "    fig = go.Figure()\n",
        "    x_axis = dates if dates is not None else list(range(len(y_true)))\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=x_axis, y=y_true, mode='lines', name='Actual Output'))\n",
        "    fig.add_trace(go.Scatter(x=x_axis, y=y_pred, mode='lines', name=f'Predicted Output ({label})'))\n",
        "\n",
        "    fig.update_layout(\n",
        "        title=title,\n",
        "        xaxis_title=\"Time\" if dates is not None else \"Time Step (15-min intervals)\",\n",
        "        yaxis_title=\"Output (kW)\",\n",
        "        legend=dict(x=0, y=1.1, orientation='h'),\n",
        "        height=400,\n",
        "        width=900,\n",
        "        margin=dict(l=40, r=40, t=40, b=40)\n",
        "    )\n",
        "\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtyC1hQBlG8w"
      },
      "source": [
        "### Plot (Prediction vs Actual)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xurry_xalG8w"
      },
      "outputs": [],
      "source": [
        "def plot_and_save_predictions(datetime_series, y_true, y_pred,\n",
        "                              filename, ylabel=\"Energy (kW)\"):\n",
        "\n",
        "    # Include .png\n",
        "    filename_png = f\"{filename}\" + \".png\"\n",
        "\n",
        "    # Create plot\n",
        "    fig, ax = plt.subplots(figsize=(10, 5))\n",
        "    ax.plot(datetime_series, y_true, label='Actual', linewidth=2)\n",
        "    ax.plot(datetime_series, y_pred, label='Predicted', color='red', linewidth=2)\n",
        "\n",
        "    ax.set_ylabel(ylabel, fontsize=12)\n",
        "    ax.grid(True, linestyle='--', alpha=0.7)\n",
        "    ax.legend(loc='upper right', fontsize=12)\n",
        "\n",
        "    fig.autofmt_xdate()  # Auto-format date labels\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save figure\n",
        "    fig.savefig(filename_png, dpi=300)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2_c3jOklG8w"
      },
      "source": [
        "### Plot (Residual Diagnostics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xE0JZ4yNlG8w"
      },
      "outputs": [],
      "source": [
        "def plot_and_save_residuals(datetime_series, y_true, y_pred,\n",
        "                            filename):\n",
        "\n",
        "    # Include .png\n",
        "    filename_png = f\"{filename}\" + \".png\"\n",
        "\n",
        "    # Calculate residuals\n",
        "    residuals = y_true - y_pred\n",
        "\n",
        "    # Create plot\n",
        "    fig = plt.figure(figsize=(12, 8))\n",
        "    gs = fig.add_gridspec(2, 2, height_ratios=[2, 1.5])\n",
        "\n",
        "    # Residuals over time\n",
        "    ax1 = fig.add_subplot(gs[0, :])\n",
        "    ax1.plot(datetime_series, residuals, color='steelblue')\n",
        "    ax1.axhline(0, linestyle='--', color='gray')\n",
        "    ax1.set_ylabel(\"Residual (kW)\")\n",
        "    ax1.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "    # ACF\n",
        "    ax2 = fig.add_subplot(gs[1, 0])\n",
        "    ax2.set_ylabel(\"ACF\")\n",
        "    plot_acf(residuals, lags=40, ax=ax2)\n",
        "\n",
        "    # Histogram\n",
        "    ax3 = fig.add_subplot(gs[1, 1])\n",
        "    ax3.set_ylabel(\"Count\")\n",
        "    sns.histplot(residuals, bins=30, kde=True, color='salmon', ax=ax3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename_png, dpi=300)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfGViHZslG8w"
      },
      "source": [
        "### Plot (Prediction vs. Actual) for a Few Selected Weeks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8U33Ct6lG8w"
      },
      "outputs": [],
      "source": [
        "\n",
        "def plot_and_save_weekly_predictions(datetime_series, y_true, y_pred,\n",
        "                                     filename,\n",
        "                                     steps_per_week=96 * 7,  # 1 week of 15-min intervals\n",
        "                                     weeks_to_plot=9):\n",
        "\n",
        "    # Include .png\n",
        "    filename_png = f\"{filename}\" + \".png\"\n",
        "\n",
        "    total_steps = len(y_true)\n",
        "    start_indices = np.linspace(0, total_steps - steps_per_week, weeks_to_plot, dtype=int)\n",
        "\n",
        "    fig, axes = plt.subplots(3, 3, figsize=(15, 10), sharey=True)\n",
        "\n",
        "    for idx, ax in enumerate(axes.flatten()):\n",
        "        start = start_indices[idx]\n",
        "        end = start + steps_per_week\n",
        "\n",
        "        # Extract corresponding dates for titles\n",
        "        start_date = datetime_series[start].strftime('%Y-%m-%d')\n",
        "        end_date = datetime_series[end - 1].strftime('%Y-%m-%d')\n",
        "\n",
        "        # Plot actual and predicted\n",
        "        ax.plot(y_true[start:end], label='Actual', linewidth=2)\n",
        "        ax.plot(y_pred[start:end], label='Predicted', color='red', linewidth=2)\n",
        "        ax.set_title(f'Week: {start_date} to {end_date}', fontsize=10)\n",
        "        ax.grid(True, linestyle='--', alpha=0.6)\n",
        "\n",
        "        if idx % 3 == 0:\n",
        "            ax.set_ylabel('Energy (kW)', fontsize=10)\n",
        "\n",
        "    fig.legend(['Actual', 'Predicted'], loc='upper center', ncol=2, fontsize=12)\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "\n",
        "    # Save figure\n",
        "    fig.savefig(filename_png, dpi=300)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save Predicitons"
      ],
      "metadata": {
        "id": "cspyWiSopfhJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def save_predictions_to_csv(datetimes, true_values, predictions, filename):\n",
        "    df = pd.DataFrame({\n",
        "        'datetime': datetimes,\n",
        "        'true': true_values,\n",
        "        'prediction': predictions\n",
        "    })\n",
        "    df.to_csv(filename, index=False)"
      ],
      "metadata": {
        "id": "UFg7koKrpn8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlHj93VLlG8w"
      },
      "source": [
        "## Model I: LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WUFSlNFJlG8w"
      },
      "source": [
        "### Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IYuANKOlG8w"
      },
      "source": [
        "#### Define Target and Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80iaRXyblG8x"
      },
      "outputs": [],
      "source": [
        "# Define features for LightGBM\n",
        "features_lgbm = [\n",
        "    'temperature',\n",
        "    'is_holiday',\n",
        "    'lag_1w', 'lag_1m', 'lag_1y',\n",
        "    'hour_sin', 'hour_cos',\n",
        "    'dayofweek_sin', 'dayofweek_cos',\n",
        "    'month_sin', 'month_cos',\n",
        "    'temp_roll_mean_1_day',\n",
        "    'temp_roll_mean_7_day',\n",
        "    'temp_roll_max_1_day',\n",
        "    'temp_roll_min_1_day',\n",
        "    'temp_roll_max_7_day',\n",
        "    'temp_roll_min_7_day'\n",
        "]\n",
        "\n",
        "# Define target\n",
        "target = 'output'\n",
        "\n",
        "# Create input and output data for LightGBM\n",
        "X_lgbm = data[features_lgbm]\n",
        "y_lgbm = data[target]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GtGCY8TSlG8x"
      },
      "source": [
        "#### Train-Test Split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQodciBtlG8x"
      },
      "source": [
        "In the case that all data should be imputed, more predictions are needed. Thus, a 50/50 split is done. Otherwise, an 80/20 split is done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qM-lxwZmlG8x"
      },
      "outputs": [],
      "source": [
        "def determine_split(impute_type):\n",
        "    if impute_type == 'all':\n",
        "        split = 0.5\n",
        "    elif impute_type == 'test':\n",
        "        split = 0.8\n",
        "    else:\n",
        "        raise ValueError(\"Invalid impute_type. Choose 'all' or 'test'.\")\n",
        "\n",
        "    return split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t7aI3odplG8x"
      },
      "outputs": [],
      "source": [
        "# Train-test split\n",
        "split = determine_split(impute_type='test')\n",
        "split_idx = int(split * len(X_lgbm))\n",
        "\n",
        "X_train_lgbm, X_test_lgbm = X_lgbm[:split_idx], X_lgbm[split_idx:]\n",
        "y_train_lgbm, y_test_lgbm = y_lgbm[:split_idx], y_lgbm[split_idx:]\n",
        "\n",
        "# Store corresponding dates for plotting\n",
        "datetime_train_lgbm = y_lgbm.index[:split_idx]\n",
        "datetime_test_lgbm = y_lgbm.index[split_idx:]\n",
        "\n",
        "print(\"X_train shape:\", X_train_lgbm.shape)\n",
        "print(\"y_train shape:\", y_train_lgbm.shape)\n",
        "\n",
        "print(\"X_test shape:\", X_test_lgbm.shape)\n",
        "print(\"y_test shape:\", y_test_lgbm.shape)\n",
        "\n",
        "# Print date intervals for train and test sets\n",
        "print(f\"Train period: {datetime_train_lgbm[0].date()} to {datetime_train_lgbm[-1].date()}\")\n",
        "print(f\"Test period:  {datetime_test_lgbm[0].date()} to {datetime_test_lgbm[-1].date()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snilzsAHlG8x"
      },
      "source": [
        "### Hyper-Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wjL9JVslG8x"
      },
      "outputs": [],
      "source": [
        "\n",
        "# from sklearn.metrics import mean_squared_error\n",
        "# import numpy as np\n",
        "\n",
        "# # Optuna Objective Function\n",
        "# def objective(trial):\n",
        "#     params = {\n",
        "#         'objective'         : 'regression',\n",
        "#         'metric'            : 'rmse',\n",
        "#         'boosting_type'     : 'gbdt',\n",
        "#         'verbosity'         : -1,\n",
        "#         'n_estimators'      : 1000,\n",
        "#         'num_leaves'        : trial.suggest_int('num_leaves', 8, 256, step=8),\n",
        "#         'max_depth'         : trial.suggest_int('max_depth', 3, 15),\n",
        "#         'min_child_samples' : trial.suggest_int('min_child_samples', 5, 100, step=5),\n",
        "#         'learning_rate'     : trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
        "#         'subsample'         : trial.suggest_float('subsample', 0.5, 1.0),\n",
        "#         'colsample_bytree'  : trial.suggest_float('colsample_bytree', 0.5, 1),\n",
        "#         'max_bin'           : trial.suggest_int('max_bin', 50, 250, step=25),\n",
        "#         'reg_alpha'         : trial.suggest_float('reg_alpha', 1e-4, 1, log=True),\n",
        "#         'reg_lambda'        : trial.suggest_float('reg_lambda', 1e-4, 1, log=True)\n",
        "#     }\n",
        "\n",
        "#     model = LGBMRegressor(**params)\n",
        "\n",
        "#     model.fit(\n",
        "#         X_train_lgbm, y_train_lgbm,\n",
        "#         eval_set=[(X_test_lgbm, y_test_lgbm)],\n",
        "#         callbacks=[\n",
        "#             early_stopping(stopping_rounds=50)]\n",
        "#     )\n",
        "\n",
        "#     preds = model.predict(X_test_lgbm)\n",
        "#     rmse = root_mean_squared_error(y_test_lgbm, preds)\n",
        "#     return rmse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwQipJ1olG8x"
      },
      "outputs": [],
      "source": [
        "# # Run Optuna optimization\n",
        "# # optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "# study = optuna.create_study(direction='minimize')\n",
        "# study.optimize(objective, n_trials=100)\n",
        "\n",
        "# # Store best parameters\n",
        "# best_params = study.best_trial.params\n",
        "# print('Best RMSE:', study.best_trial.value)\n",
        "# print('Best Params:', best_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdAZWFbxlG8x"
      },
      "source": [
        "### Train/ Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db4u-M90lG8y"
      },
      "outputs": [],
      "source": [
        "# # Train final model with Best Parameters\n",
        "# model_lgbm = LGBMRegressor(**best_params, n_estimators=1000)\n",
        "\n",
        "# # Record start time\n",
        "# start_time = time.time()\n",
        "\n",
        "# # Train the model\n",
        "# model_lgbm.fit(\n",
        "#     X_train_lgbm, y_train_lgbm,\n",
        "#     eval_set=[(X_test_lgbm, y_test_lgbm)],\n",
        "#     callbacks=[\n",
        "#         early_stopping(stopping_rounds=50)\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# # Record end time\n",
        "# end_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83k57xLrlG8y"
      },
      "outputs": [],
      "source": [
        "# # Calculate elapsed time in seconds\n",
        "# training_time_lgbm = end_time - start_time\n",
        "\n",
        "# # Format as minutes and seconds\n",
        "# training_time_minutes = training_time_lgbm / 60\n",
        "# print(f\"Training Time: {training_time_lgbm:.2f} seconds ({training_time_minutes:.2f} minutes)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2f3PWMbXlG8y"
      },
      "outputs": [],
      "source": [
        "model_lgbm = joblib.load(\"best_lgbm_model.pkl\")\n",
        "\n",
        "# Predict\n",
        "y_pred_lgbm = model_lgbm.predict(X_test_lgbm)\n",
        "\n",
        "# Evaluaion metrics\n",
        "metrics_lgbm = evaluate_regression_metrics(y_test_lgbm, y_pred_lgbm, label=\"LightGBM\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save predicitons\n",
        "save_predictions_to_csv(\n",
        "    datetimes=datetime_test_lgbm,\n",
        "    true_values=y_test_lgbm.values,\n",
        "    predictions=y_pred_lgbm,\n",
        "    filename=\"predicitions_lgbm_all.csv\")"
      ],
      "metadata": {
        "id": "VnVDBH8_pxU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9W1CXOB-lG8y"
      },
      "source": [
        "### Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfGaYq7glG8y"
      },
      "outputs": [],
      "source": [
        "# Plot interactive graph of predictions vs. actual output\n",
        "plot_predictions(y_test_lgbm.values, y_pred_lgbm, dates=datetime_test_lgbm, title=\"LGBM Predictions on Test Set\", label=\"LightGBM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hHSDslQHlG8y"
      },
      "outputs": [],
      "source": [
        "# Calculate importance\n",
        "importance = pd.Series(model_lgbm.feature_importances_, index=X_lgbm.columns)\n",
        "importance = importance.sort_values(ascending=False)\n",
        "\n",
        "# Plot importance\n",
        "plt.figure(figsize=(10, 6))\n",
        "importance.plot(kind='bar')\n",
        "plt.title(\"Feature Importance\")\n",
        "plt.ylabel(\"Importance\")\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.savefig(\"feature_importance_test.png\", dpi=300)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AtP1wOjlG8y"
      },
      "outputs": [],
      "source": [
        "# Plot and store graph of predictions vs. actual output\n",
        "plot_and_save_predictions(\n",
        "    datetime_series=datetime_test_lgbm,\n",
        "    y_true=y_test_lgbm.values,\n",
        "    y_pred=y_pred_lgbm,\n",
        "    filename=\"predictions(model=lgbm,set=test)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0kgkiz4lG8y"
      },
      "outputs": [],
      "source": [
        "# Plot and store graph of residuals\n",
        "plot_and_save_residuals(\n",
        "    datetime_series=datetime_test_lgbm,\n",
        "    y_true=y_test_lgbm.values,\n",
        "    y_pred=y_pred_lgbm,\n",
        "    filename=\"residuals(model=lgbm,set=test)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNA_wREOlG8y"
      },
      "outputs": [],
      "source": [
        "# Plot and store graph of predictions vs. actual output for a few selected weeks\n",
        "plot_and_save_weekly_predictions(\n",
        "    datetime_series=datetime_test_lgbm,\n",
        "    y_true=y_test_lgbm.values,\n",
        "    y_pred=y_pred_lgbm,\n",
        "    filename=\"predictions_week(model=lgbm,set=test)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AL0EtFZ0lG8y"
      },
      "source": [
        "## LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i17f9wJSlG8y"
      },
      "source": [
        "### Data imputation using LightGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zuw9baczlG8y"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "SEQUENCE_LEN = 96 * 7 # Number of past time steps to include in each input sequence to predict the next value\n",
        "DELAY_LENGTH = 96 * 4 # Number of unavailable time steps that must be imputed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6mDQUr-NlG8y"
      },
      "outputs": [],
      "source": [
        "# Define features\n",
        "feature_cols = [\n",
        "    'output',\n",
        "    'temperature',\n",
        "    'is_holiday',\n",
        "    'hour_sin', 'hour_cos',\n",
        "    'dayofweek_sin', 'dayofweek_cos',\n",
        "    'month_sin', 'month_cos'\n",
        "]\n",
        "\n",
        "# Convert DataFrame to NumPy Array\n",
        "data_lstm = data[feature_cols].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mO5BDQozlG8z"
      },
      "outputs": [],
      "source": [
        "# Create sequences\n",
        "def create_sequences(data, seq_length):\n",
        "    X, y = [], []\n",
        "    for i in range(seq_length, len(data)):\n",
        "        X.append(data[i - seq_length:i])\n",
        "        y.append(data[i][0])  # Target: 'output'\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "X_lstm, y_lstm = create_sequences(data_lstm, SEQUENCE_LEN)\n",
        "datetime_index_lstm = data.index[SEQUENCE_LEN:] # Adjust DateTime index to fit sequence-data\n",
        "\n",
        "print(f\"Sequence alignment check: {len(data_lstm) - len(X_lstm) == SEQUENCE_LEN}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4OfLJLplG8z"
      },
      "outputs": [],
      "source": [
        "def impute_and_split(X, y, y_pred_lgbm, delay_length, split_type='test'):\n",
        "    X_imputed = X.copy()\n",
        "\n",
        "    start_datetime = datetime_test_lgbm[0]\n",
        "    start_id = datetime_index_lstm.get_loc(start_datetime)\n",
        "    start_id_delay = start_id + delay_length\n",
        "\n",
        "    assert len(y_pred_lgbm) == len(X[start_id_delay:]) + delay_length, \"Predictions array too short for imputation.\"\n",
        "\n",
        "    # Imputation\n",
        "    for i in range(start_id_delay, len(X_imputed)):\n",
        "        preds_slice = y_pred_lgbm[i - start_id_delay : i - start_id_delay + delay_length]\n",
        "        X_imputed[i, -delay_length:, 0] = preds_slice\n",
        "\n",
        "    # Split logic:\n",
        "    #   If 'test': Only imputes the test data\n",
        "    #   If 'all': Splits data from where predictions start and performs an 80/20 train-test split\n",
        "    if split_type == 'test':\n",
        "        split_idx = start_id_delay\n",
        "\n",
        "        X_train, X_test = X_imputed[:split_idx], X_imputed[split_idx:]\n",
        "        y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "        datetime_train = datetime_index_lstm[:split_idx]\n",
        "        datetime_test = datetime_index_lstm[split_idx:]\n",
        "\n",
        "    elif split_type == 'all':\n",
        "        X_imputed = X_imputed[start_id_delay:]\n",
        "        y = y[start_id_delay:]\n",
        "        datetime_filtered = datetime_index_lstm[start_id_delay:]\n",
        "\n",
        "        split_idx = int(0.6 * len(X_imputed))\n",
        "\n",
        "        X_train, X_test = X_imputed[:split_idx], X_imputed[split_idx:]\n",
        "        y_train, y_test = y[:split_idx], y[split_idx:]\n",
        "\n",
        "        datetime_train = datetime_filtered[:split_idx]\n",
        "        datetime_test = datetime_filtered[split_idx:]\n",
        "\n",
        "    else:\n",
        "        raise ValueError(\"Invalid split_type. Choose 'all' or 'test'.\")\n",
        "\n",
        "    return X_train, X_test, y_train, y_test, datetime_train, datetime_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qlvgPYlElG8z"
      },
      "outputs": [],
      "source": [
        "X_train_lstm, X_test_lstm, y_train_lstm, y_test_lstm, datetime_train_lstm, datetime_test_lstm = impute_and_split(\n",
        "    X_lstm,\n",
        "    y_lstm,\n",
        "    y_pred_lgbm,\n",
        "    DELAY_LENGTH,\n",
        "    split_type='test'\n",
        ")\n",
        "\n",
        "print(\"X_train shape:\", X_train_lstm.shape)\n",
        "print(\"y_train shape:\", y_train_lstm.shape)\n",
        "\n",
        "print(\"X_test shape:\", X_test_lstm.shape)\n",
        "print(\"y_test shape:\", y_test_lstm.shape)\n",
        "\n",
        "# Print date intervals for train and test sets\n",
        "print(f\"Train period: {datetime_train_lstm[0].date()} to {datetime_train_lstm[-1].date()}\")\n",
        "print(f\"Test period:  {datetime_test_lstm[0].date()} to {datetime_test_lstm[-1].date()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qTBSZ9bTlG8z"
      },
      "source": [
        "### Train/ Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iqFupNjplG8z"
      },
      "outputs": [],
      "source": [
        "# Create normalization layer\n",
        "norm_layer = layers.Normalization()\n",
        "\n",
        "# Adapt it to your sequence training data (shape: (samples, timesteps, features))\n",
        "norm_layer.adapt(X_train_lstm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qoKa8qyDlG8z"
      },
      "outputs": [],
      "source": [
        "# Scale target variable\n",
        "scaler_y = MinMaxScaler()\n",
        "y_train_lstm_scaled = scaler_y.fit_transform(y_train_lstm.reshape(-1, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbPfKzzxlG8z"
      },
      "outputs": [],
      "source": [
        "# Model parameters\n",
        "input_shape = X_train_lstm.shape[1:]  # (timesteps, features)\n",
        "dropout_rate = 0\n",
        "lstm_units_full = 64\n",
        "lstm_units_half = 32\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "\n",
        "# Define the model\n",
        "model_lstm = models.Sequential([\n",
        "    Input(shape=input_shape),\n",
        "\n",
        "    norm_layer,\n",
        "\n",
        "    layers.LSTM(lstm_units_full, return_sequences=True),\n",
        "    layers.Dropout(dropout_rate),\n",
        "\n",
        "    layers.LSTM(lstm_units_half),\n",
        "    layers.Dropout(dropout_rate),\n",
        "\n",
        "    layers.Dense(1)\n",
        "])\n",
        "\n",
        "model_lstm.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Early stopping\n",
        "early_stop = callbacks.EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True)\n",
        "\n",
        "model_lstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOmuJJlUlG8z"
      },
      "outputs": [],
      "source": [
        "# Record start time\n",
        "start_time = time.time()\n",
        "\n",
        "# Train the model\n",
        "history = model_lstm.fit(\n",
        "    X_train_lstm, y_train_lstm_scaled,\n",
        "    validation_split=0.2,\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Record end time\n",
        "end_time = time.time()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVplm_rTlG8z"
      },
      "outputs": [],
      "source": [
        "# Calculate elapsed time\n",
        "training_time_lstm = end_time - start_time\n",
        "\n",
        "# Format as minutes and seconds\n",
        "training_time_minutes = training_time_lstm / 60\n",
        "print(f\"Training Time: {training_time_lstm:.2f} seconds ({training_time_minutes:.2f} minutes)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eEtrIt6tlG8z"
      },
      "outputs": [],
      "source": [
        "def plot_training_history(history, filename=\"training_history.png\"):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(history.history['loss'], label='Training Loss', linewidth=2)\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss', linewidth=2, linestyle='--')\n",
        "\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss (MSE)')\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(filename, dpi=300)\n",
        "    plt.show()\n",
        "\n",
        "# Plot the loss curves\n",
        "plot_training_history(history, filename=\"training_history(set=test).png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PBC5YWFZlG8z"
      },
      "outputs": [],
      "source": [
        "# Predict and inverse transform\n",
        "y_pred_lstm_scaled = model_lstm.predict(X_test_lstm).flatten()\n",
        "y_pred_lstm = scaler_y.inverse_transform(y_pred_lstm_scaled.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Evaluaion metrics\n",
        "metrics = evaluate_regression_metrics(y_test_lstm, y_pred_lstm, label=\"LSTM\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save predicitons\n",
        "save_predictions_to_csv(\n",
        "    datetimes=datetime_test_lstm,\n",
        "    true_values=y_test_lstm,\n",
        "    predictions=y_pred_lstm,\n",
        "    filename=\"predicitions_lstm_test.csv\")"
      ],
      "metadata": {
        "id": "6sNNvu81rB4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPWJHXiClG80"
      },
      "source": [
        "### Plots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ICzjiPFxlG80"
      },
      "outputs": [],
      "source": [
        "# Plot interactive graph of predictions vs. actual output\n",
        "plot_predictions(y_test_lstm, y_pred_lstm, dates=datetime_test_lstm, title=\"LSTM Predictions on Test Set\", label=\"LSTM\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXK7QX-ilG80"
      },
      "outputs": [],
      "source": [
        "# Plot and store graph of predictions vs. actual output\n",
        "plot_and_save_predictions(\n",
        "    datetime_series=datetime_test_lstm,\n",
        "    y_true=y_test_lstm,\n",
        "    y_pred=y_pred_lstm,\n",
        "    filename=\"predictions(model=lstm,set=test)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgJkVEU3lG80"
      },
      "outputs": [],
      "source": [
        "# Plot and store graph of residuals\n",
        "plot_and_save_residuals(\n",
        "    datetime_series=datetime_test_lstm,\n",
        "    y_true=y_test_lstm,\n",
        "    y_pred=y_pred_lstm,\n",
        "    filename=\"residuals(model=lstm,set=test)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "phYTpewqlG80"
      },
      "outputs": [],
      "source": [
        "# Plot and store graph of predictions vs. actual output for a few selected weeks\n",
        "plot_and_save_weekly_predictions(\n",
        "    datetime_series=datetime_test_lstm,\n",
        "    y_true=y_test_lstm,\n",
        "    y_pred=y_pred_lstm,\n",
        "    filename=\"predictions_week(model=lstm,set=test)\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zXAz-mgwn0pE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}